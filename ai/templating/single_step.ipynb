{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only do if key not defined\n",
    "if 'key' not in locals():\n",
    "    key = !op read \"op://private/sfm openai api key/password\"\n",
    "    assert len(key) == 1\n",
    "    key = key[0]\n",
    "assert len(key) == 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import json\n",
    "from pprint import pprint\n",
    "from pydantic import BaseModel\n",
    "\n",
    "openai.api_key = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunTest(BaseModel):\n",
    "    include_visual_observation: bool\n",
    "    agent_test_code: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_test():\n",
    "    path = r\"D:\\Repos\\Minecraft\\Forge\\SuperFactoryManager\\src\\gametest\\java\\ca\\teamdman\\sfm\\ai\\OpenDoorTest.java\"\n",
    "    with open(path, \"r\") as f:\n",
    "        return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_test(content: str):\n",
    "    path = r\"D:\\Repos\\Minecraft\\Forge\\SuperFactoryManager\\src\\gametest\\java\\ca\\teamdman\\sfm\\ai\\OpenDoorTest.java\"\n",
    "    with open(path, \"w\") as f:\n",
    "        f.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        a\n",
      "        b\n",
      "        c\n"
     ]
    }
   ],
   "source": [
    "def indent_text(text, spaces=4):\n",
    "    space_str = \" \" * spaces\n",
    "    return \"\\n\".join(f\"{space_str}{line}\" for line in text.split(\"\\n\"))\n",
    "print(indent_text(\"a\\nb\\nc\",8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def with_agent_content(test: str, new_content: str) -> str:\n",
    "    \"\"\"\n",
    "    We want to remove any previous attempts at the test\n",
    "\n",
    "    // begin agent code\n",
    "    item.setPos(Vec3.atCenterOf(helper.absolutePos(pressurePlatePos).offset(0,3,0)));\n",
    "    // end agent code\n",
    "\n",
    "    should remove the content between the two comments\n",
    "    \"\"\"\n",
    "    region_start = \"        // begin agent code\"\n",
    "    region_end = \"        // end agent code\"\n",
    "    start = test.find(region_start)\n",
    "    end = test.find(region_end)\n",
    "    return test[:start+len(region_start)] + \"\\n\" + new_content + (\"\\n\" if new_content != \"\" else \"\") + test[end:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_agent_content(test: str) -> str:\n",
    "    region_start = \"        // begin agent code\"\n",
    "    region_end = \"        // end agent code\"\n",
    "    start = test.find(region_start)\n",
    "    end = test.find(region_end)\n",
    "    return test[start+len(region_start)+1:end]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# begin hotkey_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyautogui\n",
    "import pygetwindow as gw\n",
    "from time import sleep\n",
    "import pyperclip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focus_intellij():\n",
    "    try:\n",
    "        title = next(x for x in gw.getAllTitles() if \"TestChambers.java\" in x)\n",
    "        windows = gw.getWindowsWithTitle(title)\n",
    "        assert len(windows) > 0, f\"Window not found: {title}\"\n",
    "        windows[0].activate()\n",
    "    except Exception as e:\n",
    "        print(f\"Error focusing window: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_building():\n",
    "    return pyautogui.pixel(1947, 622) == (95, 173, 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_build_output():\n",
    "    # store cursor position\n",
    "    x, y = pyautogui.position()\n",
    "    # click and drag from 2890, 638 to 2895, 638 to select text without activating links\n",
    "    pyautogui.moveTo(2890, 638)\n",
    "    pyautogui.mouseDown()\n",
    "    pyautogui.moveTo(2895, 638)\n",
    "    pyautogui.mouseUp()\n",
    "    pyautogui.hotkey('ctrl', 'a')\n",
    "    pyautogui.hotkey('ctrl', 'c')\n",
    "    # restore cursor position\n",
    "    pyautogui.moveTo(x, y)\n",
    "    return pyperclip.paste().replace('\\r', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_happy_build_output(output):\n",
    "    happy = \"\"\"\n",
    "Executing pre-compile tasksâ€¦\n",
    "Running 'before' tasks\n",
    "Checking sources\n",
    "Running 'after' tasks\n",
    "Finished, saving cachesâ€¦\n",
    "Executing post-compile tasksâ€¦\n",
    "Finished, saving cachesâ€¦\n",
    "    \"\"\".strip()\n",
    "    return output.strip() == happy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hot_reload():\n",
    "    print(\"[Hot Reload] Focusing IntelliJ\")\n",
    "    focus_intellij()\n",
    "    sleep(0.5)\n",
    "    print(\"[Hot Reload] Trigger hot reload\")\n",
    "    pyautogui.hotkey('ctrl', 'alt', 'num0')\n",
    "    print(\"[Hot Reload] Wait for build to finish\")\n",
    "    while is_building():\n",
    "        sleep(0.1)\n",
    "    sleep(0.5)\n",
    "    print(\"[Hot Reload] Copy build output\")\n",
    "    output = get_build_output()\n",
    "    success = is_happy_build_output(output)\n",
    "    print(f\"[Hot Reload] Build output succeeded: {success}\")\n",
    "    return success, output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# end hotkey_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package ca.teamdman.sfm.ai;\n",
      "\n",
      "import ca.teamdman.sfm.SFM;\n",
      "import ca.teamdman.sfm.SFMGameTestBase;\n",
      "import net.minecraft.core.BlockPos;\n",
      "import net.minecraft.gametest.framework.GameTest;\n",
      "import net.minecraft.gametest.framework.GameTestHelper;\n",
      "import net.minecraft.world.entity.item.ItemEntity;\n",
      "import net.minecraft.world.item.ItemStack;\n",
      "import net.minecraft.world.item.Items;\n",
      "import net.minecraft.world.level.block.Blocks;\n",
      "import net.minecraft.world.level.block.DoorBlock;\n",
      "import net.minecraft.world.phys.Vec3;\n",
      "import net.minecraftforge.gametest.GameTestHolder;\n",
      "import net.minecraftforge.gametest.PrefixGameTestTemplate;\n",
      "\n",
      "@GameTestHolder(SFM.MOD_ID)\n",
      "@PrefixGameTestTemplate(false)\n",
      "public class OpenDoorTest extends SFMGameTestBase {\n",
      "    @GameTest(template = \"3x4x3\")\n",
      "    public static void open_door(GameTestHelper helper) {\n",
      "        var pressurePlatePos = new BlockPos(0, 2, 1);\n",
      "        var redstonePos = new BlockPos(1, 2, 1);\n",
      "        var doorPos = new BlockPos(2, 2, 1);\n",
      "\n",
      "        // set the floor to iron blocks\n",
      "        for (int x = 0; x <= 2; x++) {\n",
      "            for (int z = 0; z <= 2; z++) {\n",
      "                helper.setBlock(new BlockPos(x, 1, z), Blocks.IRON_BLOCK);\n",
      "            }\n",
      "        }\n",
      "\n",
      "        // set the pressure plate\n",
      "        helper.setBlock(pressurePlatePos, Blocks.OAK_PRESSURE_PLATE);\n",
      "\n",
      "        // set the redstone dust\n",
      "        helper.setBlock(redstonePos, Blocks.REDSTONE_WIRE);\n",
      "\n",
      "        // set the door\n",
      "        helper.setBlock(doorPos, Blocks.IRON_DOOR);\n",
      "        \n",
      "        var item = new ItemEntity(\n",
      "                helper.getLevel(),\n",
      "                redstonePos.getX(),\n",
      "                redstonePos.getY(),\n",
      "                redstonePos.getZ(),\n",
      "                new ItemStack(Items.DIAMOND)\n",
      "        );\n",
      "        item.setDeltaMovement(0, 0, 0);\n",
      "\n",
      "        // is this the right position? There might be an improvement here ðŸ‘€\n",
      "        item.setPos(Vec3.atCenterOf(helper.absolutePos(doorPos).offset(0, 3, 0)));\n",
      "        // begin agent code\n",
      "        // end agent code\n",
      "        helper.getLevel().addFreshEntity(item);\n",
      "        helper.succeedWhen(() -> {\n",
      "            helper.assertBlockProperty(doorPos, DoorBlock.OPEN, true);\n",
      "        });\n",
      "    }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(with_agent_content(read_test(), ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"The assistant is tasked with solving puzzles in a Minecraft game test environment, similar to the video game _Portal_. The assistant is presented a game test with some code at the beginning and end of the test that the agent can not change. The agent is responsible for replacing the code in the middle of the test to cause the test to succeed.\"},\n",
    "    {\"role\": \"user\", \"content\": f\"Current test content:\\n```java\\n{with_agent_content(read_test(), '')}```\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_convo(messages):\n",
    "    content = \"\"\n",
    "    for msg in messages:\n",
    "        content += f\"# ~=~ {msg['role']}\\n{msg['content']}\\n\"\n",
    "        if \"function_call\" in msg:\n",
    "            content += f\"---\\n{msg['function_call']}\\n\"\n",
    "    with open(\"convo.md\", \"w\") as f:\n",
    "        f.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-85OuIDnhjVOAnV5MoJg8xm5cooaub\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1696298074,\n",
      "  \"model\": \"gpt-4-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": null,\n",
      "        \"function_call\": {\n",
      "          \"name\": \"run_test\",\n",
      "          \"arguments\": \"{\\n  \\\"include_visual_observation\\\": true,\\n  \\\"agent_test_code\\\": \\\"item.setPos(Vec3.atCenterOf(helper.absolutePos(pressurePlatePos).offset(0, 3, 0)));\\\"\\n}\"\n",
      "        }\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 678,\n",
      "    \"completion_tokens\": 46,\n",
      "    \"total_tokens\": 724\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response0 = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=messages,\n",
    "    functions=[\n",
    "        {\n",
    "          \"name\": \"run_test\",\n",
    "          \"description\": \"Run the test with the agent code block substituted for the provided content. Requesting a visual observation will slow down the process through a dependency on humans.\",\n",
    "          \"parameters\": RunTest.model_json_schema()\n",
    "        },\n",
    "    ],\n",
    "    function_call={\"name\": \"run_test\"}\n",
    ")\n",
    "print(response0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item.setPos(Vec3.atCenterOf(helper.absolutePos(pressurePlatePos).offset(0, 3, 0)));\n"
     ]
    }
   ],
   "source": [
    "run = RunTest(**json.loads(response0.choices[0][\"message\"][\"function_call\"][\"arguments\"]))\n",
    "print(run.agent_test_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Hot Reload] Focusing IntelliJ\n",
      "Error focusing window: \n",
      "[Hot Reload] Trigger hot reload\n",
      "[Hot Reload] Wait for build to finish\n",
      "[Hot Reload] Copy build output\n",
      "[Hot Reload] Build output succeeded: True\n"
     ]
    }
   ],
   "source": [
    "write_test(with_agent_content(read_test(), indent_text(run.agent_test_code, 12)))\n",
    "success, build_output = hot_reload()\n",
    "if not success:\n",
    "    print(build_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# begin runner_comms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "msgdir = Path(\"./messages\")\n",
    "msgdir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test():\n",
    "    print(\"[Run Test] Running test, ensure you ran `/sfm_ai listen` in Minecraft\")\n",
    "    # touch messages/run.txt\n",
    "    (msgdir / \"run.txt\").touch()\n",
    "\n",
    "    from time import sleep\n",
    "    # wait for the file to have test results appended\n",
    "    while not (msgdir / \"run.txt\").stat().st_size > 0:\n",
    "        sleep(0.1)\n",
    "    \n",
    "    # read the file\n",
    "    with open(msgdir / \"run.txt\", \"r\") as f:\n",
    "        results = f.read()\n",
    "\n",
    "    archive_content = get_agent_content(read_test()) + \"\\n\\n\" + results\n",
    "    \n",
    "    # clean up the file by renaming it with the time\n",
    "    from datetime import datetime\n",
    "    now = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    (msgdir / f\"run_{now}.txt\").write_text(archive_content)\n",
    "    (msgdir / \"run.txt\").unlink()\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# end runner_comms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run Test] Running test, ensure you ran `/sfm_ai listen` in Minecraft\n"
     ]
    }
   ],
   "source": [
    "if success:\n",
    "    test_output = run_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'open_door passed! (544ms)'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'function', 'name': 'run_test', 'content': 'D:\\\\Repos\\\\Minecraft\\\\Forge\\\\SuperFactoryManager\\\\src\\\\gametest\\\\java\\\\ca\\\\teamdman\\\\sfm\\\\ai\\\\OpenDoorTest.java:54: error: no suitable method found for setDeltaMovement(Vec3,Vec3)\\n            item.setDeltaMovement(Vec3.atLowerCornerOf(helper.absolutePos(pressurePlatePos).offset(0, 3, 0)), Vec3.ZERO);\\n                ^\\n    method Entity.setDeltaMovement(Vec3) is not applicable\\n      (actual and formal argument lists differ in length)\\n    method Entity.setDeltaMovement(double,double,double) is not applicable\\n      (actual and formal argument lists differ in length)'}\n"
     ]
    }
   ],
   "source": [
    "fn0 = {\n",
    "    \"role\": \"function\",\n",
    "    \"name\": \"run_test\",\n",
    "    \"content\": build_output if not success else test_output,\n",
    "}\n",
    "print(fn0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-7zen4yURBM38izZ9c10YKZ2vfsOaC\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1694929162,\n",
      "  \"model\": \"gpt-4-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": null,\n",
      "        \"function_call\": {\n",
      "          \"name\": \"run_test\",\n",
      "          \"arguments\": \"{\\n\\\"include_visual_observation\\\": false,\\n\\\"agent_test_code\\\": \\\"item.setPos(Vec3.atCenterOf(helper.absolutePos(pressurePlatePos).offset(0, 0, 0)));\\\"\\n}\"\n",
      "        }\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 914,\n",
      "    \"completion_tokens\": 44,\n",
      "    \"total_tokens\": 958\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response1 = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        *messages,\n",
    "        response0.choices[0][\"message\"],\n",
    "        fn0,\n",
    "    ],\n",
    "    functions=[\n",
    "        {\n",
    "          \"name\": \"run_test\",\n",
    "          \"description\": \"Run the test with the agent code block substituted for the provided content. Requesting a visual observation will slow down the process through a dependency on humans.\",\n",
    "          \"parameters\": RunTest.model_json_schema()\n",
    "        },\n",
    "    ],\n",
    "    function_call={\"name\": \"run_test\"}\n",
    ")\n",
    "print(response1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Hot Reload] Focusing IntelliJ\n",
      "Error focusing window: \n",
      "[Hot Reload] Trigger hot reload\n",
      "[Hot Reload] Wait for build to finish\n",
      "[Hot Reload] Copy build output\n",
      "[Hot Reload] Build output succeeded: False\n",
      "D:\\Repos\\Minecraft\\Forge\\SuperFactoryManager\\src\\gametest\\java\\ca\\teamdman\\sfm\\ai\\OpenDoorTest.java:54: error: no suitable method found for setDeltaMovement(Vec3,Vec3)\n",
      "            item.setDeltaMovement(Vec3.atLowerCornerOf(helper.absolutePos(pressurePlatePos).offset(0, 3, 0)), Vec3.ZERO);\n",
      "                ^\n",
      "    method Entity.setDeltaMovement(Vec3) is not applicable\n",
      "      (actual and formal argument lists differ in length)\n",
      "    method Entity.setDeltaMovement(double,double,double) is not applicable\n",
      "      (actual and formal argument lists differ in length)\n"
     ]
    }
   ],
   "source": [
    "if response1.choices[0][\"message\"][\"content\"] is not None:\n",
    "    print(response1.choices[0][\"message\"][\"content\"])\n",
    "if \"function_call\" in response1.choices[0][\"message\"]:\n",
    "    run = RunTest(**json.loads(response1.choices[0][\"message\"][\"function_call\"][\"arguments\"]))\n",
    "    write_test(with_agent_content(read_test(), indent_text(run.agent_test_code, 12)))\n",
    "    success, build_output = hot_reload()\n",
    "    if not success:\n",
    "        print(build_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run Test] Running test, ensure you ran `/sfm_ai listen` in Minecraft\n"
     ]
    }
   ],
   "source": [
    "if success:\n",
    "    test_output = run_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn1 = {\n",
    "    \"role\": \"function\",\n",
    "    \"name\": \"run_test\",\n",
    "    \"content\": build_output if not success else test_output,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-7zel30gj3aHdyi8E3vbE0n3dpvD9H\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1694929037,\n",
      "  \"model\": \"gpt-4-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"In the game, the pressure plate becomes \\\"powered\\\" when something touches or is on top of it, this sends a \\\"redstone signal\\\" to nearby blocks, in this case, the door, forcing it to open. \\n\\nThe item entity must land on the pressure plate to press it and open the door with the consequent redstone signal. Currently, the program tries to spawn the item above the door which is at position (2, 2, 1). Therefore, we need to spawn the item just above the pressure plate at position (0, 3, 1) so that it falls onto the pressure plate.\\n\\nLet's adjust the code accordingly.\",\n",
      "        \"function_call\": {\n",
      "          \"name\": \"run_test\",\n",
      "          \"arguments\": \"{\\n\\\"include_visual_observation\\\": false,\\n\\\"agent_test_code\\\": \\\"item.setPos(Vec3.atCenterOf(helper.absolutePos(pressurePlatePos).offset(0, 3, 0)));\\\"\\n}\"\n",
      "        }\n",
      "      },\n",
      "      \"finish_reason\": \"function_call\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 878,\n",
      "    \"completion_tokens\": 186,\n",
      "    \"total_tokens\": 1064\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response2 = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        *messages,\n",
    "        response0.choices[0][\"message\"],\n",
    "        fn0,\n",
    "        response1.choices[0][\"message\"],\n",
    "        fn1\n",
    "    ],\n",
    "    functions=[\n",
    "        {\n",
    "          \"name\": \"run_test\",\n",
    "          \"description\": \"Run the test with the agent code block substituted for the provided content. Requesting a visual observation will slow down the process through a dependency on humans.\",\n",
    "          \"parameters\": RunTest.model_json_schema()\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "print(response2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the game, the pressure plate becomes \"powered\" when something touches or is on top of it, this sends a \"redstone signal\" to nearby blocks, in this case, the door, forcing it to open. \n",
      "\n",
      "The item entity must land on the pressure plate to press it and open the door with the consequent redstone signal. Currently, the program tries to spawn the item above the door which is at position (2, 2, 1). Therefore, we need to spawn the item just above the pressure plate at position (0, 3, 1) so that it falls onto the pressure plate.\n",
      "\n",
      "Let's adjust the code accordingly.\n",
      "[Hot Reload] Focusing IntelliJ\n",
      "Error focusing window: \n",
      "[Hot Reload] Trigger hot reload\n",
      "[Hot Reload] Wait for build to finish\n",
      "[Hot Reload] Copy build output\n",
      "[Hot Reload] Build output succeeded: True\n",
      "[Run Test] Running test, ensure you ran `/sfm_ai listen` in Minecraft\n",
      "test_out open_door failed! Expected property open to be true, was false at 2,-58,4 (relative: 2,2,1) (t=60)\n"
     ]
    }
   ],
   "source": [
    "if response2.choices[0][\"message\"][\"content\"] is not None:\n",
    "    print(response2.choices[0][\"message\"][\"content\"])\n",
    "if \"function_call\" in response2.choices[0][\"message\"]:\n",
    "    run = RunTest(**json.loads(response2.choices[0][\"message\"][\"function_call\"][\"arguments\"]))\n",
    "    write_test(with_agent_content(read_test(), indent_text(run.agent_test_code, 12)))\n",
    "    success, build_output = hot_reload()\n",
    "    if not success:\n",
    "        print(build_output)\n",
    "    if success:\n",
    "        test_output = run_test()\n",
    "        print(\"test_out\", test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_convo([\n",
    "    *messages,\n",
    "    response0.choices[0][\"message\"],\n",
    "    fn0,\n",
    "    response1.choices[0][\"message\"],\n",
    "    fn1,\n",
    "    response2.choices[0][\"message\"],\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sfm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "0.0.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
