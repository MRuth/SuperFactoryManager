{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = !op read \"op://private/sfm openai api key/password\"\n",
    "assert len(key) == 1\n",
    "key = key[0]\n",
    "assert len(key) == 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import json\n",
    "from pprint import pprint\n",
    "from pydantic import BaseModel\n",
    "\n",
    "openai.api_key = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunTest(BaseModel):\n",
    "    include_visual_observation: bool\n",
    "    agent_test_code: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_test():\n",
    "    path = r\"D:\\Repos\\Minecraft\\Forge\\SuperFactoryManager\\src\\gametest\\java\\ca\\teamdman\\sfm\\ai\\TestChambers.java\"\n",
    "    with open(path, \"r\") as f:\n",
    "        return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_test(content: str):\n",
    "    path = r\"D:\\Repos\\Minecraft\\Forge\\SuperFactoryManager\\src\\gametest\\java\\ca\\teamdman\\sfm\\ai\\TestChambers.java\"\n",
    "    with open(path, \"w\") as f:\n",
    "        f.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        a\n",
      "        b\n",
      "        c\n"
     ]
    }
   ],
   "source": [
    "def indent_text(text, spaces=4):\n",
    "    space_str = \" \" * spaces\n",
    "    return \"\\n\".join(f\"{space_str}{line}\" for line in text.split(\"\\n\"))\n",
    "print(indent_text(\"a\\nb\\nc\",8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def with_agent_content(test: str, new_content: str):\n",
    "    \"\"\"\n",
    "    We want to remove any previous attempts at the test\n",
    "\n",
    "    // begin agent code\n",
    "    item.setPos(Vec3.atCenterOf(helper.absolutePos(pressurePlatePos).offset(0,3,0)));\n",
    "    // end agent code\n",
    "\n",
    "    should remove the content between the two comments\n",
    "    \"\"\"\n",
    "    region_start = \"        // begin agent code\"\n",
    "    region_end = \"        // end agent code\"\n",
    "    start = test.find(region_start)\n",
    "    end = test.find(region_end)\n",
    "    return test[:start+len(region_start)] + \"\\n\" + new_content + (\"\\n\" if new_content != \"\" else \"\") + test[end:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# begin hotkey_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyautogui\n",
    "import pygetwindow as gw\n",
    "from time import sleep\n",
    "import pyperclip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focus_intellij():\n",
    "    try:\n",
    "        title = next(x for x in gw.getAllTitles() if \"TestChambers.java\" in x)\n",
    "        windows = gw.getWindowsWithTitle(title)\n",
    "        assert len(windows) > 0, f\"Window not found: {title}\"\n",
    "        windows[0].activate()\n",
    "    except Exception as e:\n",
    "        print(f\"Error focusing window: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_building():\n",
    "    return pyautogui.pixel(1947, 622) == (95, 173, 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_build_output():\n",
    "    # click and drag from 2890, 638 to 2895, 638 to select text without activating links\n",
    "    pyautogui.moveTo(2890, 638)\n",
    "    pyautogui.mouseDown()\n",
    "    pyautogui.moveTo(2895, 638)\n",
    "    pyautogui.mouseUp()\n",
    "    pyautogui.hotkey('ctrl', 'a')\n",
    "    pyautogui.hotkey('ctrl', 'c')\n",
    "    return pyperclip.paste().replace('\\r', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_happy_build_output(output):\n",
    "    happy = \"\"\"\n",
    "Executing pre-compile tasks…\n",
    "Running 'before' tasks\n",
    "Checking sources\n",
    "Running 'after' tasks\n",
    "Finished, saving caches…\n",
    "Executing post-compile tasks…\n",
    "Finished, saving caches…\n",
    "    \"\"\".strip()\n",
    "    return output.strip() == happy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hot_reload():\n",
    "    print(\"[Hot Reload] Focusing IntelliJ\")\n",
    "    focus_intellij()\n",
    "    print(\"[Hot Reload] Trigger hot reload\")\n",
    "    pyautogui.hotkey('ctrl', 'alt', 'num0')\n",
    "    print(\"[Hot Reload] Wait for build to finish\")\n",
    "    while is_building():\n",
    "        sleep(0.1)\n",
    "    sleep(0.5)\n",
    "    print(\"[Hot Reload] Copy build output\")\n",
    "    output = get_build_output()\n",
    "    success = is_happy_build_output(output)\n",
    "    print(f\"[Hot Reload] Build output succeeded: {success}\")\n",
    "    return success, output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# end hotkey_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"The assistant is tasked with solving puzzles in a Minecraft game test environment, similar to the video game _Portal_. The assistant is presented a game test with some code at the beginning and end of the test that the agent can not change. The agent is responsible for replacing the code in the middle of the test to cause the test to succeed.\"},\n",
    "    {\"role\": \"user\", \"content\": f\"Current test content:\\n```java\\n{with_agent_content(read_test(), '')}```\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_convo(messages):\n",
    "    content = \"\"\n",
    "    for msg in messages:\n",
    "        content += f\"# ~=~ {msg['role']}\\n{msg['content']}\\n\"\n",
    "        if \"function_call\" in msg:\n",
    "            content += f\"---\\n{msg['function_call']}\\n\"\n",
    "    with open(\"convo.md\", \"w\") as f:\n",
    "        f.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_convo(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-7x7jjU2ikWslapdTt95ZGeGA7AEzH\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1694325447,\n",
      "  \"model\": \"gpt-4-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": null,\n",
      "        \"function_call\": {\n",
      "          \"name\": \"run_test\",\n",
      "          \"arguments\": \"{\\n\\\"include_visual_observation\\\": false,\\n\\\"agent_test_code\\\": \\\"helper.getLevel().setBlockAndUpdate(pressurePlatePos, Blocks.OAK_PRESSURE_PLATE.defaultBlockState().setValue(PressurePlateBlock.POWERED, true));\\\"\\n}\"\n",
      "        }\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 1558,\n",
      "    \"completion_tokens\": 53,\n",
      "    \"total_tokens\": 1611\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response0 = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=messages,\n",
    "    functions=[\n",
    "        {\n",
    "          \"name\": \"run_test\",\n",
    "          \"description\": \"Run the test with the agent code block substituted for the provided content. Requesting a visual observation will slow down the process through a dependency on humans.\",\n",
    "          \"parameters\": RunTest.model_json_schema()\n",
    "        },\n",
    "    ],\n",
    "    function_call={\"name\": \"run_test\"}\n",
    ")\n",
    "print(response0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Focusing IntelliJ\n",
      "Trigger hot reload\n",
      "Wait for build to finish\n",
      "Copy build output\n",
      "Build output succeeded: False\n",
      "D:\\Repos\\Minecraft\\Forge\\SuperFactoryManager\\src\\gametest\\java\\ca\\teamdman\\sfm\\ai\\TestChambers.java:94: error: cannot find symbol\n",
      "            helper.getLevel().setBlockAndUpdate(pressurePlatePos, Blocks.OAK_PRESSURE_PLATE.defaultBlockState().setValue(PressurePlateBlock.POWERED, true));\n",
      "                                                                                                                         ^\n",
      "  symbol:   variable PressurePlateBlock\n",
      "  location: class TestChambers\n"
     ]
    }
   ],
   "source": [
    "run = RunTest(**json.loads(response0.choices[0][\"message\"][\"function_call\"][\"arguments\"]))\n",
    "write_test(with_agent_content(read_test(), indent_text(run.agent_test_code, 12)))\n",
    "success, output = hot_reload()\n",
    "if not success:\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'function', 'name': 'run_test', 'content': 'build successful'}\n"
     ]
    }
   ],
   "source": [
    "fn0 = {\n",
    "    \"role\": \"function\",\n",
    "    \"name\": \"run_test\",\n",
    "    \"content\": output if not success else \"build successful\",\n",
    "}\n",
    "print(fn0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-7x7kAMFmigqNnPCGKXQeT7tAhZKOa\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1694325474,\n",
      "  \"model\": \"gpt-4-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": null,\n",
      "        \"function_call\": {\n",
      "          \"name\": \"run_test\",\n",
      "          \"arguments\": \"{\\n\\\"include_visual_observation\\\": false,\\n\\\"agent_test_code\\\": \\\"helper.getLevel().setBlockAndUpdate(pressurePlatePos, Blocks.OAK_PRESSURE_PLATE.defaultBlockState().setValue(BlockStateProperties.POWERED, true));\\\"\\n}\"\n",
      "        }\n",
      "      },\n",
      "      \"finish_reason\": \"function_call\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 1720,\n",
      "    \"completion_tokens\": 57,\n",
      "    \"total_tokens\": 1777\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response1 = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        *messages,\n",
    "        response0.choices[0][\"message\"],\n",
    "        fn0,\n",
    "    ],\n",
    "    functions=[\n",
    "        {\n",
    "          \"name\": \"run_test\",\n",
    "          \"description\": \"Run the test with the agent code block substituted for the provided content. Requesting a visual observation will slow down the process through a dependency on humans.\",\n",
    "          \"parameters\": RunTest.model_json_schema()\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "print(response1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Hot Reload] Focusing IntelliJ\n",
      "[Hot Reload] Trigger hot reload\n",
      "[Hot Reload] Wait for build to finish\n",
      "[Hot Reload] Copy build output\n",
      "[Hot Reload] Build output succeeded: True\n"
     ]
    }
   ],
   "source": [
    "if response1.choices[0][\"message\"][\"content\"] is not None:\n",
    "    print(response1.choices[0][\"message\"][\"content\"])\n",
    "if \"function_call\" in response1.choices[0][\"message\"]:\n",
    "    run = RunTest(**json.loads(response1.choices[0][\"message\"][\"function_call\"][\"arguments\"]))\n",
    "    write_test(with_agent_content(read_test(), indent_text(run.agent_test_code, 12)))\n",
    "    success, output = hot_reload()\n",
    "    if not success:\n",
    "        print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn1 = {\n",
    "    \"role\": \"function\",\n",
    "    \"name\": \"run_test\",\n",
    "    \"content\": output if not success else \"build successful\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_convo([\n",
    "    *messages,\n",
    "    response0.choices[0][\"message\"],\n",
    "    fn0,\n",
    "    response1.choices[0][\"message\"],\n",
    "    fn1\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sfm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
